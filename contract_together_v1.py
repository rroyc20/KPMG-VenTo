# -*- coding: utf-8 -*-
"""최종_전달_파일_0214v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X3_Q1NeAxppHPe4QRI0eIlIjwILSmryn
"""

!pip install transformers
!pip install pypdf2

import re
from PyPDF2 import PdfReader
from transformers import pipeline

class Contract_Model():
    def __init__(self, pdf_file, threshold):
        self.pdf_file = pdf_file
        self.threshold = threshold
        self.result = {}

    def predict(self):

      def find_element_index(lst, element_prefix):
          for index, element in enumerate(lst):
              if element.startswith(element_prefix):
                  return index
          return -1

      def add_element_prefix(lst):
          prefix_pattern = re.compile(r"\n *제[0-9]+조\(.*?(?=\n)")
          last_prefix = None
          for index, element in enumerate(lst):
              match = re.search(prefix_pattern, element)
              if match:
                  last_prefix = match.group()
              elif last_prefix:
                  lst[index] = last_prefix + element
          return lst

      def clean_pdf_text(x):
          x = x.replace('\n',' ') # \n 제거
          x = x.replace('"',"'") # 중간에 "" 오류 제거
          for i in ['①','②','③','④','⑤','⑥','⑦','⑧','⑨','⑩','⑪','⑫','⑬','⑭','⑮']: # 특수문자 제거
            x = x.replace(i,'')
          x = re.sub(r"- \d+ -", "", x) #페이지 제거
          x = re.sub(r'[\(\)]', '', x) # (,) 제거
          x = re.sub(r'[\[\]]', '', x) # [.] 제거
          x = re.sub(r'\s+', ' ', x) # 공백 두 칸 이상 한 칸으로 치환
          x = x.strip() # 양 끝 공백 제거
          return x

      reader = PdfReader(self.pdf_file)

      contract_text = ""
      for i in range(len(list(reader.pages))):
          page = reader.pages[i]
          contract_text += page.extract_text() 

      results = contract_text.split('.')
      contracts_raw = []
      for i in range(len(results)):
        if len(results[i]) >= 4:
          contracts_raw.append(results[i])

      result = clean_pdf_text(contract_text)
      results = result.split('.')
      contracts = []
      for i in range(len(results)):
        if len(results[i]) >= 4:
          contracts.append(results[i])

      index_start = find_element_index(contracts, ' 제2조')
      index_end = find_element_index(contracts, ' 상기 계약내용을 확인, 증명하기 위하여')

      contracts_raw = contracts_raw[index_start:index_end]
      contracts = contracts[index_start:index_end]
      contracts_raw = add_element_prefix(contracts_raw)

      classifier = pipeline("text-classification", model='skang187/Contract-new-tokenizer-mDeBERTa-v3-kor-further')

      model2_result = []
      threshold = self.threshold
      for idx,item in enumerate(contracts):
        preds = classifier(item, return_all_scores=True)
        if preds[0][1]['score'] >= threshold:
          #print(contracts_raw[idx])
          #print("불리 확률 : ", 1 - preds[0][0]['score'])
          model2_result.append([contracts_raw[idx], 1 - preds[0][0]['score'] ])
      return model2_result

    def create_lst(self):
        lst = self.predict()
        return lst